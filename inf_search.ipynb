{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inf_search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Ниже представлено решение задачи на информационный поиск. Ссылка на датасет https://www.kaggle.com/sarahdejong/lyrics (>300мб)\n",
        "2.   Он представляет собой набор, популярных песен на английском, выложенных в сеть с 2006 года. В его входит, название, атвор, текст а также неоторые другие параметры\n",
        "3.   Была произведена попытка создания модели, позволяющей по набору слов(запросу) сапоставления названием песен и их содержанию\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fb3rOaqG5_SC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ymRRQTikYO4c",
        "outputId": "1ab8ac13-e15d-4a7d-dbb5-24dae6da5d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1f3c1ef-c584-4b9b-b2c0-f2ec993bcdc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ego-remix</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>then-tell-me</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>honesty</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you-are-my-rock</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>black-culture</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Party the people, the people the party it's po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>all-i-could-do-was-cry</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>I heard\\nChurch bells ringing\\nI heard\\nA choi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>once-in-a-lifetime</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>This is just another day that I would spend\\nW...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>waiting</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Waiting, waiting, waiting, waiting\\nWaiting, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>slow-love</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Verse 1:]\\nI read all of the magazines\\nwhile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>why-don-t-you-love-me</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>N-n-now, honey\\nYou better sit down and look a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1f3c1ef-c584-4b9b-b2c0-f2ec993bcdc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1f3c1ef-c584-4b9b-b2c0-f2ec993bcdc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1f3c1ef-c584-4b9b-b2c0-f2ec993bcdc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         song  ...                                             lyrics\n",
              "index                          ...                                                   \n",
              "0                   ego-remix  ...  Oh baby, how you doing?\\nYou know I'm gonna cu...\n",
              "1                then-tell-me  ...  playin' everything so easy,\\nit's like you see...\n",
              "2                     honesty  ...  If you search\\nFor tenderness\\nIt isn't hard t...\n",
              "3             you-are-my-rock  ...  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...\n",
              "4               black-culture  ...  Party the people, the people the party it's po...\n",
              "5      all-i-could-do-was-cry  ...  I heard\\nChurch bells ringing\\nI heard\\nA choi...\n",
              "6          once-in-a-lifetime  ...  This is just another day that I would spend\\nW...\n",
              "7                     waiting  ...  Waiting, waiting, waiting, waiting\\nWaiting, w...\n",
              "8                   slow-love  ...  [Verse 1:]\\nI read all of the magazines\\nwhile...\n",
              "9       why-don-t-you-love-me  ...  N-n-now, honey\\nYou better sit down and look a...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import preprocessing\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "lyrics = pd.read_csv('/content/drive/MyDrive/lyrics.csv', sep=',', index_col='index')\n",
        "with open('/content/drive/MyDrive/popsongs.txt', 'r', encoding='utf-8') as g:\n",
        "    article_text = g.read()\n",
        "lyrics.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я решил воспользоватьтся методом Word2vec, потому что, на мой взгляд он достаточно релевантен в данной задаче, прежде всего я составил словарь из слов песен по средствам данного метода и использовал для этого текст всех песен"
      ],
      "metadata": {
        "id": "sG39KYAw6pR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the dataset\n",
        "processed_article = article_text.replace('/n', '')\n",
        "processed_article = processed_article.lower()\n",
        "processed_article = re.sub('[^a-zA-Z]', ' ', processed_article )\n",
        "processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
        "\n",
        "all_sentences = nltk.sent_tokenize(processed_article)\n",
        "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
      ],
      "metadata": {
        "id": "gMvJPaiGUlg_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Stop Words\n",
        "from nltk.corpus import stopwords\n",
        "for i in range(len(all_words)):\n",
        "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
      ],
      "metadata": {
        "id": "LJUiReAQUobx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = Word2Vec(all_words, min_count=2)\n",
        "vocabulary = list(word2vec.wv.vocab)\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "id": "oHWxnVRUUqWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374515e1-a29b-41d3-def4-f42ae0941dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В словарь я определил те слова, которые встречались более чем 2 раза в совокупности всех текстов, однако из них были исключены stopwords и прочее, мешающие анализу в будущем, также я пришел к выводу, что обучение модели на основе датсета песен могло быть не лучшей идеей, так как она могла давать довольно четкие предсказания сходств слов 'man', 'boy', но не показывать сходства в более банальных случаях. Решение этого сводилось бы к использования созданного набор векторов схожести для слов от Word2vec, либо обучение на стороннем датасете"
      ],
      "metadata": {
        "id": "jDE6T7Zm8Kwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trash\n",
        "def text_listing(text):\n",
        "  text = text.replace('/n', '')\n",
        "  text = text.lower()\n",
        "  text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  text = text.split(' ')\n",
        "  \n",
        "my_answer = 'Stressed russia'\n",
        "my_list = text_listing(my_answer)\n",
        "print(my_list)\n",
        "\n",
        "name_list =[]\n",
        "for i in my_list:\n",
        "  for j in name_list:\n",
        "    pass\n",
        "\n",
        "word2vec.wv.similarity('man', 'boy')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmEwkIcRdFB_",
        "outputId": "e02ba6cf-a07e-459f-eecb-51f3e57bbfea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stressed', 'russia']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7641143"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также я решил использовать метод обратного индексирования, который заключается в сопоставления слов текстам, в которых они встречаются, это обеспечивает снижения набора текстов, необходимых для сравнения с запросом. \n",
        "\n",
        "\n",
        "Данную функцию я реализовал как пересечение множеств в которых втсречается индексы, при условии ими выдачи колличества запросов не более указанного (зависит от изначальной феличины датасета и необходимой степени сжатия), а также измерении объема списка текстов с представленными индексом и возврат их по мере увеличения встречаемости слов в данных текстах  "
      ],
      "metadata": {
        "id": "r2ZiVE7I9iyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexing(list_index, df):\n",
        "    dict_index = dict.fromkeys(list_index)\n",
        "    for i in list_index:\n",
        "      for j in df.lyrics:\n",
        "        if type(j) != float:\n",
        "          text_listing(j) \n",
        "          if i in j: \n",
        "            if dict_index[i]==None: dict_index[i] = j\n",
        "            else: dict_index[i] = dict_index[i].append(j)\n",
        "    return dict_index\n",
        "\n",
        "\n",
        "dict_index = indexing(vocabulary,lyrics)\n"
      ],
      "metadata": {
        "id": "Nf3kQPPtXoAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexing_intersect(query):\n",
        "  query = text_listing(query)\n",
        "  query_index = set(dict_index)\n",
        "  for i in query: query_index = (query_index & indexing[i])\n",
        "  if len(query_index) >= 10000:\n",
        "    query_index = set(dict_index)\n",
        "    i_list = []\n",
        "    for i in query: \n",
        "      i_list = i_list.append([len(indexing[i]), indexing[i]])\n",
        "    i_list = i_list.sort(reverse=True)\n",
        "    for i in i_list:\n",
        "      while query_index & i_list[1]<=10000:\n",
        "        query_index = query_index & i_list[1]\n",
        "  return list(query_index)\n",
        "\n"
      ],
      "metadata": {
        "id": "larPSaUwxhVy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я в процессе решения задачи использовал разные метрики, в том числе euclidean_similarity для векторов слов запроса и слов текстов, где выводилось:\n",
        "\n",
        "\n",
        "\n",
        "**mean(max(euclidean_similarity(x(i), y(j), j in lyrics.shape[0]), i in range(len(index_dictionary))))**\n",
        "\n",
        "\n",
        "После чего происходило сравнение данной метрики для проиндексированных текстов"
      ],
      "metadata": {
        "id": "m4gsSVKrftJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def euclidean_distance(x, y):\n",
        "#     x = preprocessing.normalize([x])[0]\n",
        "#     y = preprocessing.normalize([y])[0]\n",
        "#     return sum((x[i] - y[i]) ** 2 for i in range(len(x))) ** .5\n",
        "\n",
        "\n",
        "# def euclidean_similarity(x, y):\n",
        "#     return (1/(1 + euclidean_distance(x, y)))"
      ],
      "metadata": {
        "id": "5v1TW8REa4i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Но рабочий вариант остановился на метрике схожести между словами в пакете Word2vec"
      ],
      "metadata": {
        "id": "7qYQy9H1A69s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, title, text):\n",
        "        # можете здесь какие-нибудь свои поля подобавлять\n",
        "        self.title = title\n",
        "        self.text = text\n",
        "    \n",
        "    def format(self, query):\n",
        "        # возвращает пару тайтл-текст, отформатированную под запрос\n",
        "        return [self.title, self.text + ' ...']\n",
        "\n",
        "my_index=[]\n",
        "def build_index_new():\n",
        "    my_index = []\n",
        "    for i in range(lyrics.shape[0]):\n",
        "        my_index.append(Document(lyrics.song[i], lyrics.lyrics[i]))\n",
        "    return(my_index)\n",
        "\n",
        "def score(query, document):\n",
        "    score_list = [0,0]\n",
        "    for i in list(dict(word2vec.wv.most_similar(query,topn=100)).keys()):\n",
        "        if i.lower() in \" \".join(document.format(query)):\n",
        "            score_list[0] += 1\n",
        "            score_list[1] += dict(word2vec.wv.most_similar(query,topn=100)).get(i) \n",
        "    return score_list[1]/score_list[0]\n",
        "\n",
        "def retrieve(query, pot_index):\n",
        "    # возвращает начальный список релевантных документов\n",
        "    # (желательно, не бесконечный)\n",
        "    candidates = []\n",
        "    for doc in my_index:\n",
        "        if query.lower() in doc.title.lower() or query in doc.text.lower():\n",
        "            candidates.append(doc)\n",
        "    return candidates[:50]\n"
      ],
      "metadata": {
        "id": "IacZ_ngnA_db"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Была использована Mean Average Precision определяющая объем акутальных песен из вычисленных предсказаний для данного запроса, которая была использована для опеделения качества модели:"
      ],
      "metadata": {
        "id": "zsyz29kSJHN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apk(actual, predicted, k=50):\n",
        "    if not actual: return 0\n",
        "    predicted = predicted[:k]\n",
        "    result = 0\n",
        "    result_num = 0\n",
        "    for i,j in enumerate(predicted):\n",
        "        if j in actual and j not in predicted[:i]:\n",
        "            result_num += 1\n",
        "            result += result_num / (i+1)\n",
        "    return result / min(len(actual), k)\n",
        "\n",
        "\n",
        "def mapk(actual, predicted, k=50):\n",
        "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
      ],
      "metadata": {
        "id": "lkV0gA24IrkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyrics.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_wmGDU7QMAJ",
        "outputId": "c7b4975b-b2c5-4074-e3a1-88034ce4e290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "362237"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также была идея добавление среднего схожести между значимостью схожести слов между текстом и названиями и добавлением условия на авторство, если в запросе указан автор, то приоритетным становится показ именно данного автора, но представленное сопоставление песен и певцов требовало расширение певцов, за счет наличие там групп, разных псевдонимов и прочего, что привело бы к использованию сторонних данных \n"
      ],
      "metadata": {
        "id": "OOa8O9dxFurA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "from time import time\n",
        "\n",
        "app = Flask(__name__, template_folder='.')\n",
        "my_index = build_index_new()\n",
        "\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def index(my_index):\n",
        "    start_time = time()\n",
        "    query = request.args.get('query')\n",
        "    if query is None:\n",
        "        query = ''\n",
        "    my_index = my_index[indexing_intersect(query)]\n",
        "    documents = retrieve(query, my_index)\n",
        "    documents = sorted(documents, key=lambda doc: -score(query, doc))\n",
        "    results = [doc.format(query)+['%.2f' % score(query, doc)] for doc in documents] \n",
        "    return render_template(\n",
        "        '/content/drive/MyDrive/index.html',\n",
        "        time=\"%.2f\" % (time()-start_time),\n",
        "        query=query,\n",
        "        search_engine_name='Neptun Compiuter',\n",
        "        results=results\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=False, host='0.0.0.0', port=1228)\n"
      ],
      "metadata": {
        "id": "UWGb2mA-A8rj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}